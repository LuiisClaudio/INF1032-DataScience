{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste trabalho é comparar diversos métodos de classificação para a base de dados de qualidade de vinhos disponível em https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv.\n",
    "\n",
    "Vocês devem encontrar um bom modelo preditivo, variando:\n",
    "* o número e conjunto de features (atributos) utilizados\n",
    "* o método utilizado\n",
    "* a configuração do algoritmo correspondente (e.g.: número k para nearest neighbors, profundidade para árvore de decisão)\n",
    "\n",
    "Vocês devem listar algumas métricas de qualidade, tais como: precision, recall, accuracy e f1_score, e utilizar accuracy como base para a avaliação final, considerando a accuracy média de 10 iterações para cada configuração.\n",
    "\n",
    "Para assegurar que eu obterei os mesmos resultados de vocês, vocês devem estabelecer a semente para a geração dos números aleatórios (utilizados para separar os conjuntos de treinamento e teste, por exemplo), utilizando os seguintes comandos no início do seu código (podem utilizar uma outra semente):\n",
    "```\n",
    "import random\n",
    "random.seed(1001001)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1001001)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vinho_vermelho = pd.read_csv('in/winequality-red.csv', sep = ';')\n",
    "qtd_media_acc = 10\n",
    "# Data source description:\n",
    "# https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "#url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "# comment the next line if Internet access is available\n",
    "#url = 'in.data/winequality-red.csv'\n",
    "#df_vinho_vermelho = pd.read_csv(url)\n",
    "df_vinho_vermelho.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_vinho_vermelho.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 7 4 8 3]\n"
     ]
    }
   ],
   "source": [
    "#Now seperate the dataset as response variable and feature variabes\n",
    "X = df_vinho_vermelho.drop('quality', axis = 1)\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Y = df_vinho_vermelho['quality']\n",
    "outcome_labels = Y.unique()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25)\n",
    "print(outcome_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_elemetos_matrix_confusao(confm):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    total = 0\n",
    "    for i in range(len(confm)): \n",
    "        for j in range(len(confm[i])):\n",
    "            total = total + confm[i, j]\n",
    "            if i == j:\n",
    "                TP = TP + confm[i, j]\n",
    "            elif j > i:\n",
    "                FP = FP + confm[i, j]\n",
    "            elif j < i:\n",
    "                FN = FN + confm[i, j]\n",
    "        \n",
    "\n",
    "        print(confm[i])\n",
    "    TN = total - TP + FP + FN\n",
    "    return TP, FP, TN, FN\n",
    "#c_report, confm = faz_aprendizado_rfc(X_train, X_test, y_train, y_test, 300)\n",
    "#extrai_elemetos_matrix_confusao(confm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faz_aprendizado_knc(X_train, X_test, y_train, y_test, n):\n",
    "    #Create an instance of K-nearest neighbor classifier\n",
    "    knn_model = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "    KNeighborsClassifier_teste = knn_model.fit(X_train, y_train)\n",
    "    KNeighborsClassifier_resultado = knn_model.predict(X_test)\n",
    "    return classification_report(y_test, KNeighborsClassifier_resultado), confusion_matrix(y_test, KNeighborsClassifier_resultado), knn_model.score(X_train, y_train), knn_model.score(X_test, y_test)\n",
    "#c_report, confm, accuracy_train, accuracy_test = faz_aprendizado_knc(X_train, X_test, y_train, y_test, 2)\n",
    "\n",
    "def roda_knc(qtd_media_acc):\n",
    "    n = 0\n",
    "    avg_accuracy_train = 0\n",
    "    avg_accuracy_test = 0\n",
    "    melhor_c_report = melhor_confm = melhor_accuracy_train = melhor_accuracy_test = 0\n",
    "    for n_neighbors in range(2, 7): \n",
    "        for i in range(qtd_media_acc):\n",
    "            c_report, confm, accuracy_train, accuracy_test = faz_aprendizado_knc(X_train, X_test, y_train, y_test, n_neighbors)\n",
    "            avg_accuracy_train = avg_accuracy_train + accuracy_train\n",
    "            avg_accuracy_test = avg_accuracy_train + accuracy_test\n",
    "            if melhor_accuracy_test < accuracy_test:\n",
    "                n = n_neighbors\n",
    "                melhor_c_report = c_report\n",
    "                melhor_confm = confm\n",
    "                melhor_accuracy_train = accuracy_train\n",
    "                melhor_accuracy_test = accuracy_test\n",
    "        avg_accuracy_train = avg_accuracy_train/qtd_media_acc \n",
    "        avg_accuracy_test = avg_accuracy_test/qtd_media_acc\n",
    "    print('Melhor classificacao de teste tem %s centroids'%n)\n",
    "    return melhor_c_report, melhor_confm, melhor_accuracy_train, melhor_accuracy_test, avg_accuracy_train/qtd_media_acc, avg_accuracy_test/qtd_media_acc\n",
    "c_report, confm, _,_, avg_accuracy_train, avg_accuracy_test = roda_knc(qtd_media_acc)\n",
    "#print(c_report, '\\n\\n')\n",
    "\n",
    "\n",
    "print('average accuracy in training data:', '{:6.4f}'.format(avg_accuracy_train))\n",
    "print('average accuracy in test data:    ', '{:6.4f}'.format(avg_accuracy_test))\n",
    "#onfmT = confm.T\n",
    "dfConfusionMatrix = pd.DataFrame(confmT)\n",
    "dfConfusionMatrix.columns = ['true ' + str(val) for val in outcome_labels]\n",
    "dfConfusionMatrix.index   = ['pred ' + str(val) for val in outcome_labels]\n",
    "dfConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faz_aprendizado_rfc(X_train, X_test, y_train, y_test, qtd_estimators):\n",
    "    RandomForestClassifier_teste = RandomForestClassifier(n_estimators = qtd_estimators)\n",
    "    RandomForestClassifier_teste.fit(X_train, y_train)\n",
    "    RandomForestClassifier_resultado = RandomForestClassifier_teste.predict(X_test)\n",
    "    return classification_report(y_test, RandomForestClassifier_resultado) , confusion_matrix(y_test, RandomForestClassifier_resultado)\n",
    "c_report, confm = faz_aprendizado_rfc(X_train, X_test, y_train, y_test, 300)\n",
    "confmT = confm.T\n",
    "dfConfusionMatrix = pd.DataFrame(confmT)\n",
    "dfConfusionMatrix.columns = ['true ' + str(val) for val in outcome_labels]\n",
    "dfConfusionMatrix.index   = ['pred ' + str(val) for val in outcome_labels]\n",
    "dfConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN = extrai_elemetos_matrix_confusao(confm)\n",
    "# precision aka positive predictive value (PPV)\n",
    "# = what fraction of the cases that my model got are true positive?\n",
    "precision = TP / (TP + FP)\n",
    "print('precision   ', '{:7.4f}'.format(precision))\n",
    "#print('precision   ', '{:7.4f}'.format(metrics.precision_score(Y_test, Yhat)), '(from sklearn.metrics)')\n",
    "\n",
    "# recall aka sensitivity aka hit rate aka true positive rate (TPR) = TP / P\n",
    "# = what fraction of the positive cases did my model get?\n",
    "recall = TP / (TP + FN)\n",
    "print('recall      ', '{:7.4f}'.format(recall))\n",
    "#print('recall      ', '{:7.4f}'.format(metrics.recall_score(Y_test, Yhat)), '(from sklearn.metrics)')\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print('accuracy    ', '{:7.4f}'.format(accuracy))\n",
    "#print('accuracy    ', '{:7.4f}'.format(metrics.accuracy_score(Y_test, Yhat)), '(from sklearn.metrics)')\n",
    "\n",
    "F1_score = 2 * precision * recall / (precision + recall)\n",
    "print('F1_score    ', '{:7.4f}'.format(F1_score))\n",
    "#print('F1_score    ', '{:7.4f}'.format(metrics.f1_score(Y_test, Yhat)), '(from sklearn.metrics)')\n",
    "\n",
    "# specificity aka true negative rate (TNR) = TN / N\n",
    "specificity = TN / (TN + FP)\n",
    "print('specificity ', '{:7.4f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faz_aprendizado_svm(X_train, X_test, y_train, y_test):\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "    SupportVectorMachines_resultado = svc.predict(X_test)\n",
    "    return classification_report(y_test, SupportVectorMachines_resultado), confusion_matrix(y_test, SupportVectorMachines_resultado)\n",
    "faz_aprendizado_svm(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faz_aprendizado_lr(X_train, X_test, y_train, y_test):\n",
    "    LogisticRegression_teste = LogisticRegression()\n",
    "    LogisticRegression_teste.fit(X_train, y_train)\n",
    "    LogisticRegression_resultado = LogisticRegression_teste.predict(X_test)\n",
    "    return accuracy_score(y_test, LogisticRegression_resultado)\n",
    "faz_aprendizado_lr(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faz_aprendizado_dt(X_train, X_test, y_train, y_test):\n",
    "    DecisionTreeClassifier_teste = DecisionTreeClassifier()\n",
    "    DecisionTreeClassifier_teste.fit(X_train,y_train)\n",
    "    DecisionTreeClassifier_resultado = DecisionTreeClassifier_teste.predict(X_train)\n",
    "    return confusion_matrix(y_test, DecisionTreeClassifier_resultado), accuracy_score(y_test, DecisionTreeClassifier_resultado)\n",
    "#faz_aprendizado_dt(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faz_aprendizado_nb(X_train, X_test, y_train, y_test):\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train,y_train)\n",
    "    GaussianNB_resultado = nb.predict(X_test)\n",
    "    return confusion_matrix(y_test, GaussianNB_resultado), accuracy_score(y_test, GaussianNB_resultado)\n",
    "faz_aprendizado_nb(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
